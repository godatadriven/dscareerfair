{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS in Production\n",
    "In this notebook we will show how you can convert a scikit-learn model into a REST-Api hosted in a docker container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But, why? \n",
    "Docker provides us with a method to package a model and api into a single package which if it runs on your laptop, will run everywhere. Regardless if the machine hosting it run on windows, linux, or mac. Only has 1 cpu, or 32. Eg it provides us with an ideal start to test out a model in production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Install:\n",
    "* Docker (https://www.docker.com/products/docker-desktop)\n",
    "* Anaconda or\n",
    "    * scikit-learn\n",
    "    * flask\n",
    "\n",
    "\n",
    "Tutorials:\n",
    "* https://docs.docker.com/get-started/\n",
    "* https://scikit-learn.org/stable/tutorial/index.html\n",
    "* http://flask.pocoo.org/docs/1.0/tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of this Notebook\n",
    "We'll start by introducing the three components we are going to use:\n",
    "* Scikit-learn\n",
    "* Flask\n",
    "* Docker\n",
    "\n",
    "\n",
    "We will start by building a simple model. Scikit-learn is a library which makes it really easy to do so. Next, we need a method to expose this model to the world. In order to do this, we will build a REST-Api using Flask, to be able to serve predictions over http. Finally, we will use Docker to build a package (container) of our solution, readying it for deployment in the cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn Iris\n",
    "Iris is a dataset included in Scikit-learn which is used in many tutorials. It's a basic dataset, and contains measurements of three different species of Iris. With it, we will train a KNN which can classify a particular input and predict which Iris it is likely to be.\n",
    "\n",
    "Let's start with loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "dir(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the iris dataset has 5 attributes. Let's print the feature_names, and target_names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.feature_names)\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to build the KNN based on these 4 features. Sepal length/width, and Petal lenght/width.\n",
    "And with it predict which of those three Iris plants it is.\n",
    "\n",
    "Ok, let's look a the first 10 lines of the data, and target labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.target[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the data X, and the target y. \n",
    "\n",
    "Next, lets fit the KNN.\n",
    "For more information wrt the KNN, have a look here: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split iris data in train an test data\n",
    "# A random permutation, to split the data randomly\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "\n",
    "# Generate some random indices\n",
    "indices = np.random.permutation(len(iris_X))\n",
    "\n",
    "# And use them to use 10 rows for testing\n",
    "iris_X_train = iris_X[indices[:-10]]\n",
    "iris_y_train = iris_y[indices[:-10]]\n",
    "iris_X_test = iris_X[indices[-10:]]\n",
    "iris_y_test = iris_y[indices[-10:]]\n",
    "\n",
    "# Create and fit a nearest-neighbor classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(iris_X_train, iris_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a KNN. Lets use the testset to verify it the model is any good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_y_pred = knn.predict(iris_X_test)\n",
    "print(iris_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we compare those to our test set, we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit comes with scoring build in, so by calling that we get a score of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(iris_X_test, iris_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good enough for our first deployment, lets continue to Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My First Flask App\n",
    "Flask is a small framework which allows you to create a Python Webservice with only few lines.\n",
    "Let's look at this example.\n",
    "\n",
    "If it's running go to http://localhost:8080/\n",
    "\n",
    "Be sure to click the square box at the top of the screen if you're done testing it. As `app.run` is blocking and will never finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# tell flask to map this method to /\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    return \"Hello World!\"\n",
    "\n",
    "# this is a blocking call, \n",
    "# you need to interrupt the kernel to stop\n",
    "app.run(port=8080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, Flask only requires a couple of lines to get a webservice up and running. It's not suitable for big production workloads, but to test out a model on a relatively small scale it more than enough.\n",
    "\n",
    "Let's combine Flask and Scikit. And see how we can expose our trained KNN to the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Flask + Scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    from sklearn import datasets\n",
    "\n",
    "    iris = datasets.load_iris()\n",
    "\n",
    "    # Split iris data in train an test data\n",
    "    # A random permutation, to split the data randomly\n",
    "    import numpy as np\n",
    "    np.random.seed(0)\n",
    "\n",
    "    iris_X = iris.data\n",
    "    iris_y = iris.target\n",
    "\n",
    "    # Generate some random indices\n",
    "    indices = np.random.permutation(len(iris_X))\n",
    "\n",
    "    # And use them to use 10 rows for testing\n",
    "    iris_X_train = iris_X[indices[:-10]]\n",
    "    iris_y_train = iris_y[indices[:-10]]\n",
    "    iris_X_test = iris_X[indices[-10:]]\n",
    "    iris_y_test = iris_y[indices[-10:]]\n",
    "\n",
    "    # Create and fit a nearest-neighbor classifier\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(iris_X_train, iris_y_train)\n",
    "    \n",
    "    return knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same code as we used before, but wrapped into a small method. Next, we extend the Flask code to be able to serve predictions from it.\n",
    "\n",
    "Same as before, stop with the square icon.\n",
    "\n",
    "Test it out with the following url:\n",
    "http://localhost:8080/5.9/3.2/4.8/1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify\n",
    "app = Flask(__name__)\n",
    "knn = train_model()\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return \"<html>Welcome to the worlds best Iris predictor</html>\"\n",
    "\n",
    "@app.route(\"/<float:s_length>/<float:s_width>/<float:p_length>/<float:p_width>\")\n",
    "def predict(s_length, s_width, p_length, p_width):\n",
    "    result = knn.predict([[s_length, s_width, p_length, p_width]])\n",
    "    return jsonify({\"prediction\": str(iris.target_names[int(result[0])])})\n",
    "\n",
    "# this is a blocking call, \n",
    "# you need to interrupt the kernel to stop\n",
    "app.run(port=8080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small intro into Docker\n",
    "Next up, lets wrap in into a Docker package/container.\n",
    "\n",
    "First, let's see if we have docker installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List running all containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a prebuilt container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run debian:latest ls -lh /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building your own container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "# This new container is based on the latest version of debian\n",
    "FROM debian:latest\n",
    "\n",
    "# Let's create a directory inside this new container\n",
    "RUN mkdir /my_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build -t my_container ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run our own container, and see it's result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!docker run -t my_container ls -lh /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to the tutorial, lets install our flask api into a container\n",
    "First we create a file called `main.py` which contains the flask api code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile main.py\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from flask import Flask, jsonify\n",
    "\n",
    "def train_model():\n",
    "    iris = datasets.load_iris()\n",
    "    iris_X = iris.data\n",
    "    iris_y = iris.target\n",
    "\n",
    "    # Split iris data in train an test data\n",
    "    # A random permutation, to split the data randomly\n",
    "    np.random.seed(0)\n",
    "    indices = np.random.permutation(len(iris_X))\n",
    "    iris_X_train = iris_X[indices[:-10]]\n",
    "    iris_y_train = iris_y[indices[:-10]]\n",
    "    iris_X_test = iris_X[indices[-10:]]\n",
    "    iris_y_test = iris_y[indices[-10:]]\n",
    "    # Create and fit a nearest-neighbor classifier\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(iris_X_train, iris_y_train)\n",
    "    \n",
    "    return knn, iris.target_names\n",
    "\n",
    "app = Flask(__name__)\n",
    "knn, labels = train_model()\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return \"<html>Welcome to the worlds best Iris predictor</html>\"\n",
    "\n",
    "@app.route(\"/<float:s_length>/<float:s_width>/<float:p_length>/<float:p_width>\")\n",
    "def predict(s_length, s_width, p_length, p_width):\n",
    "    result = knn.predict([[s_length, s_width, p_length, p_width]])\n",
    "    return jsonify({\"prediction\": str(labels[int(result[0])])})\n",
    "\n",
    "# this is a blocking call, \n",
    "# you need to interrupt the kernel to stop\n",
    "app.run(port=8080, host=\"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Dockerfile_model\n",
    "\n",
    "# Extend the python 3.6 container\n",
    "FROM python:3.6-slim\n",
    "    \n",
    "# Install flask and scikit-learn\n",
    "RUN pip install flask scikit-learn\n",
    "\n",
    "# Copy main.py\n",
    "ADD main.py /app/main.py\n",
    "\n",
    "# And set the default command to main.py\n",
    "CMD [\"python\", \"/app/main.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build this container, but note that we pass the Dockerfile_model. We saved it to `Dockerfile_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build -t my_model_container -f Dockerfile_model ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the container, and expose it on port 8080\n",
    "\n",
    "Go to http://localhost:8080/5.9/3.2/4.8/1.8 to see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = !docker run -d -p 8080:8080 -t my_model_container\n",
    "docker_id = lines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's stop the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker rm -f $docker_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
